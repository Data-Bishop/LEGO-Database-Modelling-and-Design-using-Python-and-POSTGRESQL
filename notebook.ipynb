{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import psycopg2.extras as extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a connection to the default postgres database\n",
    "\n",
    "Take note of the use of the try and except block. This is done so as to catch any errors that may occur during the execution of the code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(host=\"localhost\", database=\"postgres\", user=\"postgres\", password=\"Databishop\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the connection to get a cursor to be used for makign queries\n",
    "try:\n",
    "    cur = conn.cursor()\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "\n",
    "# Setting autocommit for queries to True    \n",
    "conn.set_session(autocommit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the LEGO Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database \"legodb\" already exists\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating Database with name legoDB\n",
    "try:\n",
    "    cur.execute(\"CREATE DATABASE legodb\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconnecting to the LEGO Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clsoing the initial connection to the default database\n",
    "try:\n",
    "    conn.close()\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "\n",
    "# Connecting to the LEGO Database    \n",
    "try:\n",
    "    conn = psycopg2.connect(host=\"localhost\", database=\"legodb\", user=\"postgres\", password=\"Databishop\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "\n",
    "# Getting the cursor    \n",
    "try:\n",
    "    cur = conn.cursor()\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "    \n",
    "# Setting autocommit to True\n",
    "conn.set_session(autocommit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the inventories table according to the defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS inventories \\\n",
    "        (id INTEGER PRIMARY KEY,\\\n",
    "        version INTEGER,\\\n",
    "        set_number VARCHAR(50));\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the colours table according to the defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS colours \\\n",
    "        (id INTEGER PRIMARY KEY,\\\n",
    "        name VARCHAR(50),\\\n",
    "        rgb VARCHAR(6),\\\n",
    "        is_trans BOOLEAN );\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the parts table according to the defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS parts \\\n",
    "    (part_number VARCHAR(50) PRIMARY KEY,\\\n",
    "    name TEXT,\\\n",
    "    part_cat_id INTEGER);\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the sets table according to the defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS sets \\\n",
    "    (set_number VARCHAR(10) PRIMARY KEY,\\\n",
    "    name VARCHAR(50),\\\n",
    "    year INTEGER,\\\n",
    "    theme_id INTEGER,\\\n",
    "    num_parts INTEGER);\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the themes table according to the defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS themes \\\n",
    "        (id INTEGER PRIMARY KEY,\\\n",
    "        name VARCHAR(50),\\\n",
    "        parent_id INTEGER);\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the part categories table according to the defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS part_categories \\\n",
    "        (id INTEGER PRIMARY KEY,\\\n",
    "        name VARCHAR(50));\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the inventory sets table according to the defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS inventory_sets\\\n",
    "        (inventory_id INTEGER,\\\n",
    "        set_number VARCHAR(10),\\\n",
    "        quantity INTEGER);\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the inventory parts table according to the defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS inventory_parts\\\n",
    "        (inventory_id INTEGER,\\\n",
    "        part_number VARCHAR(50),\\\n",
    "        colour_id INTEGER,\\\n",
    "        quantity INTEGER,\\\n",
    "        is_spare BOOLEAN);\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding foreign key constraints to required tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a foreign key constraint to the inventories table referencing the sets table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE inventories \\\n",
    "                    ADD CONSTRAINT fk_set\\\n",
    "                    FOREIGN KEY(set_number)\\\n",
    "                    REFERENCES sets(set_number)\\\n",
    "                    ON DELETE CASCADE;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "    \n",
    "# Adding a foreign key constraint to the sets table referencing the themes table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE sets \\\n",
    "                    ADD CONSTRAINT fk_theme\\\n",
    "                    FOREIGN KEY(theme_id)\\\n",
    "                    REFERENCES themes(id)\\\n",
    "                    ON DELETE CASCADE;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "\n",
    "# Adding a foreign key constraint to the parts table referencing the parts categories table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE parts \\\n",
    "                    ADD CONSTRAINT fk_partcat\\\n",
    "                    FOREIGN KEY(part_cat_id)\\\n",
    "                    REFERENCES part_categories(id)\\\n",
    "                    ON DELETE CASCADE;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "    \n",
    "# Adding a foreign key constraint to the inventory parts table referencing the inventories categories table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE inventory_parts \\\n",
    "                    ADD CONSTRAINT fk_inventory\\\n",
    "                    FOREIGN KEY(inventory_id)\\\n",
    "                    REFERENCES inventories(id)\\\n",
    "                    ON DELETE CASCADE;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "    \n",
    "# Adding a foreign key constraint to the inventory parts table referencing the parts table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE inventory_parts \\\n",
    "                    ADD CONSTRAINT fk_partnum\\\n",
    "                    FOREIGN KEY(part_number)\\\n",
    "                    REFERENCES parts(part_number)\\\n",
    "                    ON DELETE CASCADE;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "    \n",
    "# Adding a foreign key constraint to the inventory parts table referencing the colours table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE inventory_parts \\\n",
    "                    ADD CONSTRAINT fk_colourid\\\n",
    "                    FOREIGN KEY(colour_id)\\\n",
    "                    REFERENCES colours(id)\\\n",
    "                    ON DELETE CASCADE;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "    \n",
    "# Adding a foreign key constraint to the inventory sets table referencing the inventories table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE inventory_sets \\\n",
    "                    ADD CONSTRAINT fk_inventoryid\\\n",
    "                    FOREIGN KEY(inventory_id)\\\n",
    "                    REFERENCES inventories(id)\\\n",
    "                    ON DELETE CASCADE;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "    \n",
    "# Adding a foreign key constraint to the inventory sets table referencing the sets table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE inventory_sets \\\n",
    "                    ADD CONSTRAINT fk_setnum\\\n",
    "                    FOREIGN KEY(set_number)\\\n",
    "                    REFERENCES sets(set_number)\\\n",
    "                    ON DELETE CASCADE;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the csv files into pandas dataframes and importing the dataframes into their corresponding tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the 'execute_df_values' function\n",
    "\n",
    "def execute_df_values(conn, df, table): \n",
    "\n",
    "\t# The function converts the DataFrame `df` into a list of tuples (`tuples`), where each tuple represents a row in the DataFrame\n",
    "\ttuples = [tuple(x) for x in df.to_numpy()] \n",
    "\n",
    "\t# Constructing a comma-separated string of column names from the DataFrame.\n",
    "\tcols = ','.join(list(df.columns)) \n",
    "\n",
    " \n",
    "\t# SQL query to insert data into the specific\n",
    "\tquery = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols)\n",
    " \n",
    "\ttry: \n",
    "\t\textras.execute_values(cur, query, tuples) \n",
    "\texcept (Exception, psycopg2.DatabaseError) as e: \n",
    "\t\tprint(e) \n",
    "\t\tconn.rollback() \n",
    "\t\treturn \n",
    "\n",
    "\tprint(\"the dataframe is inserted\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the 'get_column_names' function  \n",
    " \n",
    "def get_column_names(table_name):\n",
    "    \n",
    "    # The function returns the column names for specific tables in the database\n",
    "    try:\n",
    "        # Query to get column names from information_schema.columns\n",
    "        query = f\"SELECT column_name FROM information_schema.columns WHERE table_name = '{table_name}';\"\n",
    "        \n",
    "        # Execute the query\n",
    "        cur.execute(query)\n",
    "        \n",
    "        # Fetch all the results as a list of tuples and extract column names\n",
    "        db_column_names = [column[0] for column in cur.fetchall()]\n",
    "        \n",
    "        return db_column_names\n",
    "    except psycopg2.Error as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting data into the part categories table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe is inserted\n"
     ]
    }
   ],
   "source": [
    "# Reading the part categories data in a dataframe\n",
    "part_categories_df = pd.read_csv('part_categories.csv')\n",
    "\n",
    "# Inserting the data from the dataframe into the corresponding table\n",
    "execute_df_values(conn, part_categories_df, 'part_categories')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting data into the parts table\n",
    "The 'part_num' column in the dataframe has to have the same column name as the 'part_number' column in the database table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe is inserted\n"
     ]
    }
   ],
   "source": [
    "# Reading the part categories data in a dataframe\n",
    "parts_df = pd.read_csv('parts.csv')\n",
    "\n",
    "# Renaming the part_num column in the dataframe to correspond with the part_number column in the parts table\n",
    "column_mapping = {\n",
    "    'part_num': 'part_number'\n",
    "}\n",
    "\n",
    "parts_df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Inserting the data from the dataframe into the corresponding table\n",
    "execute_df_values(conn, parts_df, 'parts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting data into the colours table\n",
    "The 'f' and 't' values in the 'is_trans' column need to be converted to their boolean alternatives before being inserted into the colours table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe is inserted\n"
     ]
    }
   ],
   "source": [
    "# Reading the colours data into a dataframe\n",
    "colours_df = pd.read_csv('colors.csv')\n",
    "\n",
    "# Replacing the respective values with Boolean False/True\n",
    "colours_df.loc[colours_df['is_trans'] == 'f', 'is_trans'] = False\n",
    "colours_df.loc[colours_df['is_trans'] == 't', 'is_trans'] = True\n",
    "\n",
    "# Inserting the data from the dataframe into the corresponding table\n",
    "execute_df_values(conn, colours_df, 'colours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting data into the themes table\n",
    "\n",
    "The 'parent_id' column contains some missing values. These values have to be taken care of so that the data could be successfully inserted into the themes table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe is inserted\n"
     ]
    }
   ],
   "source": [
    "# Reading the part categories data in a dataframe\n",
    "themes_df = pd.read_csv('themes.csv')\n",
    "\n",
    "# Converting NaN values to Zero, and casting the dtype of the column to an integer\n",
    "themes_df['parent_id'] = themes_df['parent_id'].fillna(0).astype(int)\n",
    "\n",
    "# Inserting the data from the dataframe into the corresponding table\n",
    "execute_df_values(conn, themes_df, 'themes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting data into the sets table\n",
    "The 'set_num' column in the dataframe has to have the same column name as the 'set_number' column in the database table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: value too long for type character varying(50)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading the sets data in a dataframe\n",
    "sets_df = pd.read_csv('sets.csv')\n",
    "\n",
    "# Renaming the set_num column in the dataframe to correspond with the set_number column in the sets table\n",
    "column_mapping = {\n",
    "    'set_num': 'set_number'\n",
    "}\n",
    "\n",
    "sets_df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Inserting the data from the dataframe into the corresponding table\n",
    "execute_df_values(conn, sets_df, 'sets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error above indicates that some data to be inserted exceeds the data type constraint which represents VARCHAR(50) and which was set on the 'name' column. The data type for the said column needs to be changed to accomodate the data to be inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the data type of the 'name' column in the sets table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE sets\\\n",
    "                ALTER COLUMN name\\\n",
    "                TYPE VARCHAR;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: value too long for type character varying(10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inserting the data from the dataframe into the corresponding table\n",
    "execute_df_values(conn, sets_df, 'sets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error above indicates that some data to be inserted exceeds the data type constraint which represents VARCHAR(10) and which was set on the 'set_number' column. The data type for the said column needs to be changed to accomodate the data to be inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the data type of the 'set_number' column in the sets table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE sets\\\n",
    "                ALTER COLUMN set_number\\\n",
    "                TYPE VARCHAR;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe is inserted\n"
     ]
    }
   ],
   "source": [
    "# Inserting the data from the dataframe into the corresponding table\n",
    "execute_df_values(conn, sets_df, 'sets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting data into the inventories table\n",
    "\n",
    "Since the inventories table references the sets table from its 'set_number' column, hence I need to update the data type to VARCHAR, to correspond with that of the sets table.\n",
    "\n",
    "Also, the 'set_num' column in the dataframe has to have the same column name as the 'set_number' column in the database table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the data type of the 'set_number' column in the inventories table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE inventories\\\n",
    "                ALTER COLUMN set_number\\\n",
    "                TYPE VARCHAR;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe is inserted\n"
     ]
    }
   ],
   "source": [
    "# Reading the inventories data in a dataframe\n",
    "inventories_df = pd.read_csv('inventories.csv')\n",
    "\n",
    "# Renaming the set_num column in the dataframe to correspond with the set_number column in the sets table\n",
    "column_mapping = {\n",
    "    'set_num': 'set_number'\n",
    "}\n",
    "\n",
    "inventories_df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Inserting the data from the dataframe into the corresponding table\n",
    "execute_df_values(conn, inventories_df, 'inventories')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting data into the inventory sets table\n",
    "\n",
    "Since the inventory sets table references the sets table from its 'set_number' column, hence I need to update the data type to VARCHAR, to correspond with that of the sets table.\n",
    "\n",
    "Also, the 'set_num' column in the dataframe has to have the same column name as the 'set_number' column in the database table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the data type of the 'set_number' column in the inventory sets table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE inventory_sets\\\n",
    "                ALTER COLUMN set_number\\\n",
    "                TYPE VARCHAR;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe is inserted\n"
     ]
    }
   ],
   "source": [
    "# Reading the inventories data in a dataframe\n",
    "inventory_sets_df = pd.read_csv('inventory_sets.csv')\n",
    "\n",
    "# Renaming the set_num column in the dataframe to correspond with the set_number column in the sets table\n",
    "column_mapping = {\n",
    "    'set_num': 'set_number'\n",
    "}\n",
    "\n",
    "inventory_sets_df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Inserting the data from the dataframe into the corresponding table\n",
    "execute_df_values(conn, inventory_sets_df, 'inventory_sets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting data into the inventory parts table\n",
    "The 'f' and 't' values in the 'is_spare' column need to be converted to their boolean alternatives before being inserted into the inventory_parts table. \n",
    "\n",
    "Also, the 'part_num' and 'color_id' columns in the dataframe must have the same column names as the 'part_number' and 'colour_id' columns in the database table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: insert or update on table \"inventory_parts\" violates foreign key constraint \"fk_partnum\"\n",
      "DETAIL:  Key (part_number)=(3650) is not present in table \"parts\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading the inventory parts data into a dataframe\n",
    "inventory_parts_df = pd.read_csv('inventory_parts.csv')\n",
    "\n",
    "column_mapping = {\n",
    "    'part_num' : 'part_number',\n",
    "    'color_id' : 'colour_id'\n",
    "}\n",
    "\n",
    "inventory_parts_df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Replacing the respective values with Boolean False/True\n",
    "inventory_parts_df.loc[inventory_parts_df['is_spare'] == 'f', 'is_spare'] = False\n",
    "inventory_parts_df.loc[inventory_parts_df['is_spare'] == 't', 'is_spare'] = True\n",
    "\n",
    "# Inserting the data from the dataframe into the corresponding table\n",
    "execute_df_values(conn, inventory_parts_df, 'inventory_parts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has been observed that they are some records in inventory_parts, with part numbers not in the parts table. Hence, it is recommended to remove the foreign key relationship between the inventory_parts and parts tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"ALTER TABLE inventory_parts\\\n",
    "                DROP CONSTRAINT fk_partnum\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe is inserted\n"
     ]
    }
   ],
   "source": [
    "# Inserting the data from the dataframe into the corresponding table\n",
    "execute_df_values(conn, inventory_parts_df, 'inventory_parts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this is to validate if all the data has been successfully imported into their respective tables in the LEGO database.\n",
    "\n",
    "\n",
    "**Validation conditions**\n",
    "\n",
    "\n",
    "Number of rows in each pandas dataframe = Number of records in the corresponding database table\n",
    "\n",
    "Number of columns in each pandas dataframe = Number of fields in the corresponding database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the 'validate_tables' function\n",
    "def validate_tables(df, table_name):\n",
    "    \n",
    "    # Displaying validation message\n",
    "    print(f\"Validating the {table_name} table...\\nValidating the first condition...\")\n",
    "    \n",
    "    # Query to return the number of records\n",
    "    records_query = f\"SELECT COUNT(*) FROM {table_name};\"\n",
    "    \n",
    "    # Executing the records query\n",
    "    try:\n",
    "        cur.execute(records_query)\n",
    "    except psycopg2.Error as e:\n",
    "        print(e)\n",
    "    \n",
    "    # Fetching the number of records in the database table\n",
    "    record_count = cur.fetchone()[0]\n",
    "    \n",
    "    # Fetching the number of rows in the dataframe\n",
    "    row_count = df.shape[0]\n",
    "    \n",
    "    # Validating condition 1\n",
    "    if (record_count == row_count):\n",
    "        print(f\"The {table_name} table has passed the first validation condition \\nNumber of table records = {record_count}\\n\\nValidating the second condition...\")\n",
    "        \n",
    "        # Query to return the number of fields\n",
    "        fields_query = f\"SELECT COUNT(*) FROM information_schema.columns WHERE table_name = '{table_name}';\"\n",
    "        \n",
    "        # Executing the records query\n",
    "        try:\n",
    "            cur.execute(fields_query)\n",
    "        except psycopg2.Error as e:\n",
    "            print(e) \n",
    "            \n",
    "        # Fetch the number of fields in the database table\n",
    "        field_count = cur.fetchone()[0]   \n",
    "        \n",
    "        #Fetching the number of columns in the dataframe\n",
    "        column_count = df.shape[1] \n",
    "        \n",
    "        # Validating condition 2\n",
    "        if (field_count == column_count):\n",
    "            print(f\"The {table_name} table has passed the second validation condition \\nNumber of table fields = {field_count}\")\n",
    "        else:\n",
    "            print(f\"The {table_name} table has failed the second validation condition \\nNumber of table fields = {field_count} \\nNumber of dataframe columns = {column_count}\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"The {table_name} table has failed the first validation condition \\nNumber of table records = {record_count} \\nNumber of dataframe rows = {row_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating the inventories table...\n",
      "Validating the first condition...\n",
      "The inventories table has passed the first validation condition \n",
      "Number of table records = 11681\n",
      "\n",
      "Validating the second condition...\n",
      "The inventories table has passed the second validation condition \n",
      "Number of table fields = 3\n"
     ]
    }
   ],
   "source": [
    "# Validating the 'inventories' table\n",
    "validate_tables(inventories_df, 'inventories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating the inventory_parts table...\n",
      "Validating the first condition...\n",
      "The inventory_parts table has passed the first validation condition \n",
      "Number of table records = 580251\n",
      "\n",
      "Validating the second condition...\n",
      "The inventory_parts table has passed the second validation condition \n",
      "Number of table fields = 5\n"
     ]
    }
   ],
   "source": [
    "# Validating the 'inventory_parts' table\n",
    "validate_tables(inventory_parts_df, 'inventory_parts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating the inventory_sets table...\n",
      "Validating the first condition...\n",
      "The inventory_sets table has passed the first validation condition \n",
      "Number of table records = 2846\n",
      "\n",
      "Validating the second condition...\n",
      "The inventory_sets table has passed the second validation condition \n",
      "Number of table fields = 3\n"
     ]
    }
   ],
   "source": [
    "# Validating the 'inventory_sets' table\n",
    "validate_tables(inventory_sets_df, 'inventory_sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating the parts table...\n",
      "Validating the first condition...\n",
      "The parts table has passed the first validation condition \n",
      "Number of table records = 25993\n",
      "\n",
      "Validating the second condition...\n",
      "The parts table has passed the second validation condition \n",
      "Number of table fields = 3\n"
     ]
    }
   ],
   "source": [
    "# Validating the 'parts' table\n",
    "validate_tables(parts_df, 'parts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating the part_categories table...\n",
      "Validating the first condition...\n",
      "The part_categories table has passed the first validation condition \n",
      "Number of table records = 57\n",
      "\n",
      "Validating the second condition...\n",
      "The part_categories table has passed the second validation condition \n",
      "Number of table fields = 2\n"
     ]
    }
   ],
   "source": [
    "# Validating the 'part categories' table\n",
    "validate_tables(part_categories_df, 'part_categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating the colours table...\n",
      "Validating the first condition...\n",
      "The colours table has passed the first validation condition \n",
      "Number of table records = 135\n",
      "\n",
      "Validating the second condition...\n",
      "The colours table has passed the second validation condition \n",
      "Number of table fields = 4\n"
     ]
    }
   ],
   "source": [
    "# Validating the 'colours' table\n",
    "validate_tables(colours_df, 'colours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating the sets table...\n",
      "Validating the first condition...\n",
      "The sets table has passed the first validation condition \n",
      "Number of table records = 11673\n",
      "\n",
      "Validating the second condition...\n",
      "The sets table has passed the second validation condition \n",
      "Number of table fields = 5\n"
     ]
    }
   ],
   "source": [
    "# Validating the 'sets' table\n",
    "validate_tables(sets_df, 'sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating the themes table...\n",
      "Validating the first condition...\n",
      "The themes table has passed the first validation condition \n",
      "Number of table records = 614\n",
      "\n",
      "Validating the second condition...\n",
      "The themes table has passed the second validation condition \n",
      "Number of table fields = 3\n"
     ]
    }
   ],
   "source": [
    "# Validating the 'themes' table\n",
    "validate_tables(themes_df, 'themes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
