{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import psycopg2.extras as extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a connection to the default postgres database\n",
    "\n",
    "Take note of the use of the try and except block. This is done so as to catch any errors that may occur during the execution of the code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(host=\"localhost\", database=\"postgres\", user=\"postgres\", password=\"Databishop\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the connection to get a cursor to be used for makign queries\n",
    "try:\n",
    "    cur = conn.cursor()\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "\n",
    "# Setting autocommit for queries to True    \n",
    "conn.set_session(autocommit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the LEGO Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database \"legodb\" already exists\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating Database with name legoDB\n",
    "try:\n",
    "    cur.execute(\"CREATE DATABASE legodb\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconnecting to the LEGO Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clsoing the initial connection to the default database\n",
    "try:\n",
    "    conn.close()\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "\n",
    "# Connecting to the LEGO Database    \n",
    "try:\n",
    "    conn = psycopg2.connect(host=\"localhost\", database=\"legodb\", user=\"postgres\", password=\"Databishop\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "\n",
    "# Getting the cursor    \n",
    "try:\n",
    "    cur = conn.cursor()\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "    \n",
    "# Setting autocommit to True\n",
    "conn.set_session(autocommit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the inventories table according to the defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS inventories \\\n",
    "        (id INTEGER PRIMARY KEY,\\\n",
    "        version INTEGER,\\\n",
    "        set_number VARCHAR(50));\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the colours table according to the defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS colours \\\n",
    "        (id INTEGER PRIMARY KEY,\\\n",
    "        name VARCHAR(50),\\\n",
    "        rgb VARCHAR(6),\\\n",
    "        is_trans BOOLEAN );\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the parts table according to the defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS parts \\\n",
    "    (part_number VARCHAR(50) PRIMARY KEY,\\\n",
    "    name TEXT,\\\n",
    "    part_cat_id INTEGER);\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the sets table according to the defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS sets \\\n",
    "    (set_number VARCHAR(10) PRIMARY KEY,\\\n",
    "    name VARCHAR(50),\\\n",
    "    year INTEGER,\\\n",
    "    theme_id INTEGER,\\\n",
    "    num_parts INTEGER);\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the themes table according to the defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS themes \\\n",
    "        (id INTEGER PRIMARY KEY,\\\n",
    "        name VARCHAR(50),\\\n",
    "        parent_id INTEGER);\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the part categories table according to the defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS part_categories \\\n",
    "        (id INTEGER PRIMARY KEY,\\\n",
    "        name VARCHAR(50));\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the inventory sets table according to the defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS inventory_sets\\\n",
    "        (inventory_id INTEGER,\\\n",
    "        set_number VARCHAR(10),\\\n",
    "        quantity INTEGER);\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the inventory parts table according to the defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS inventory_parts\\\n",
    "        (inventory_id INTEGER,\\\n",
    "        part_number VARCHAR(50),\\\n",
    "        colour_id INTEGER,\\\n",
    "        quantity INTEGER,\\\n",
    "        is_spare BOOLEAN);\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding foreign key constraints to required tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a foreign key constraint to the inventories table referencing the sets table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE inventories \\\n",
    "                    ADD CONSTRAINT fk_set\\\n",
    "                    FOREIGN KEY(set_number)\\\n",
    "                    REFERENCES sets(set_number)\\\n",
    "                    ON DELETE CASCADE;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "    \n",
    "# Adding a foreign key constraint to the sets table referencing the themes table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE sets \\\n",
    "                    ADD CONSTRAINT fk_theme\\\n",
    "                    FOREIGN KEY(theme_id)\\\n",
    "                    REFERENCES themes(id)\\\n",
    "                    ON DELETE CASCADE;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "\n",
    "# Adding a foreign key constraint to the parts table referencing the parts categories table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE parts \\\n",
    "                    ADD CONSTRAINT fk_partcat\\\n",
    "                    FOREIGN KEY(part_cat_id)\\\n",
    "                    REFERENCES part_categories(id)\\\n",
    "                    ON DELETE CASCADE;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "    \n",
    "# Adding a foreign key constraint to the inventory parts table referencing the inventories categories table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE inventory_parts \\\n",
    "                    ADD CONSTRAINT fk_inventory\\\n",
    "                    FOREIGN KEY(inventory_id)\\\n",
    "                    REFERENCES inventories(id)\\\n",
    "                    ON DELETE CASCADE;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "    \n",
    "# Adding a foreign key constraint to the inventory parts table referencing the parts table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE inventory_parts \\\n",
    "                    ADD CONSTRAINT fk_partnum\\\n",
    "                    FOREIGN KEY(part_number)\\\n",
    "                    REFERENCES parts(part_number)\\\n",
    "                    ON DELETE CASCADE;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "    \n",
    "# Adding a foreign key constraint to the inventory parts table referencing the colours table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE inventory_parts \\\n",
    "                    ADD CONSTRAINT fk_colourid\\\n",
    "                    FOREIGN KEY(colour_id)\\\n",
    "                    REFERENCES colours(id)\\\n",
    "                    ON DELETE CASCADE;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "    \n",
    "# Adding a foreign key constraint to the inventory sets table referencing the inventories table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE inventory_sets \\\n",
    "                    ADD CONSTRAINT fk_inventoryid\\\n",
    "                    FOREIGN KEY(inventory_id)\\\n",
    "                    REFERENCES inventories(id)\\\n",
    "                    ON DELETE CASCADE;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)\n",
    "    \n",
    "# Adding a foreign key constraint to the inventory sets table referencing the sets table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE inventory_sets \\\n",
    "                    ADD CONSTRAINT fk_setnum\\\n",
    "                    FOREIGN KEY(set_number)\\\n",
    "                    REFERENCES sets(set_number)\\\n",
    "                    ON DELETE CASCADE;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the csv files into pandas dataframes and importing the dataframes into their corresponding tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the 'execute_df_values' function\n",
    "\n",
    "def execute_df_values(conn, df, table): \n",
    "\n",
    "\t# The function converts the DataFrame `df` into a list of tuples (`tuples`), where each tuple represents a row in the DataFrame\n",
    "\ttuples = [tuple(x) for x in df.to_numpy()] \n",
    "\n",
    "\t# Constructing a comma-separated string of column names from the DataFrame.\n",
    "\tcols = ','.join(list(df.columns)) \n",
    "\n",
    " \n",
    "\t# SQL query to insert data into the specific\n",
    "\tquery = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols)\n",
    " \n",
    "\ttry: \n",
    "\t\textras.execute_values(cur, query, tuples) \n",
    "\texcept (Exception, psycopg2.DatabaseError) as e: \n",
    "\t\tprint(e) \n",
    "\t\tconn.rollback() \n",
    "\t\treturn \n",
    "\n",
    "\tprint(\"the dataframe is inserted\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the 'get_column_names' function  \n",
    " \n",
    "def get_column_names(table_name):\n",
    "    \n",
    "    # The function returns the column names for specific tables in the database\n",
    "    try:\n",
    "        # Query to get column names from information_schema.columns\n",
    "        query = f\"SELECT column_name FROM information_schema.columns WHERE table_name = '{table_name}';\"\n",
    "        \n",
    "        # Execute the query\n",
    "        cur.execute(query)\n",
    "        \n",
    "        # Fetch all the results as a list of tuples and extract column names\n",
    "        db_column_names = [column[0] for column in cur.fetchall()]\n",
    "        \n",
    "        return db_column_names\n",
    "    except psycopg2.Error as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting data into the part categories table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe is inserted\n"
     ]
    }
   ],
   "source": [
    "# Reading the part categories data in a dataframe\n",
    "part_categories_df = pd.read_csv('part_categories.csv')\n",
    "\n",
    "# Inserting the data from the dataframe into the corresponding table\n",
    "execute_df_values(conn, part_categories_df, 'part_categories')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting data into the parts table\n",
    "The 'part_num' column in the dataframe has to have the same column name as the 'part_number' column in the database table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe is inserted\n"
     ]
    }
   ],
   "source": [
    "# Reading the part categories data in a dataframe\n",
    "parts_df = pd.read_csv('parts.csv')\n",
    "\n",
    "# Renaming the part_num column in the dataframe to correspond with the part_number column in the parts table\n",
    "column_mapping = {\n",
    "    'part_num': 'part_number'\n",
    "}\n",
    "\n",
    "parts_df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Inserting the data from the dataframe into the corresponding table\n",
    "execute_df_values(conn, parts_df, 'parts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting data into the colours table\n",
    "The 'f' and 't' values in the 'is_trans' column need to be converted to their boolean alternatives before being inserted into the colours table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe is inserted\n"
     ]
    }
   ],
   "source": [
    "# Reading the colours data into a dataframe\n",
    "colours_df = pd.read_csv('colors.csv')\n",
    "\n",
    "# Replacing the respective values with Boolean False/True\n",
    "colours_df.loc[colours_df['is_trans'] == 'f', 'is_trans'] = False\n",
    "colours_df.loc[colours_df['is_trans'] == 't', 'is_trans'] = True\n",
    "\n",
    "# Inserting the data from the dataframe into the corresponding table\n",
    "execute_df_values(conn, colours_df, 'colours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting data into the themes table\n",
    "\n",
    "The 'parent_id' column contains some missing values. These values have to be taken care of so that the data could be successfully inserted into the themes table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe is inserted\n"
     ]
    }
   ],
   "source": [
    "# Reading the part categories data in a dataframe\n",
    "themes_df = pd.read_csv('themes.csv')\n",
    "\n",
    "# Converting NaN values to Zero, and casting the dtype of the column to an integer\n",
    "themes_df['parent_id'] = themes_df['parent_id'].fillna(0).astype(int)\n",
    "\n",
    "# Inserting the data from the dataframe into the corresponding table\n",
    "execute_df_values(conn, themes_df, 'themes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: value too long for type character varying(50)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading the sets data in a dataframe\n",
    "sets_df = pd.read_csv('sets.csv')\n",
    "\n",
    "# Renaming the set_num column in the dataframe to correspond with the set_number column in the sets table\n",
    "column_mapping = {\n",
    "    'set_num': 'set_number'\n",
    "}\n",
    "\n",
    "sets_df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# Inserting the data from the dataframe into the corresponding table\n",
    "execute_df_values(conn, sets_df, 'sets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error above indicates that some data to be inserted exceeds the data type constraint which represents VARCHAR(50) and which was set on the 'name' column. The data type for the said column needs to be changed to accomodate the data to be inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the data type of the 'name' column in the sets table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE sets\\\n",
    "                ALTER COLUMN name\\\n",
    "                TYPE VARCHAR;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: value too long for type character varying(10)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inserting the data from the dataframe into the corresponding table\n",
    "execute_df_values(conn, sets_df, 'sets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error above indicates that some data to be inserted exceeds the data type constraint which represents VARCHAR(10) and which was set on the 'set_number' column. The data type for the said column needs to be changed to accomodate the data to be inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the data type of the 'set_number' column in the sets table\n",
    "try:\n",
    "    cur.execute(\"ALTER TABLE sets\\\n",
    "                ALTER COLUMN set_number\\\n",
    "                TYPE VARCHAR;\")\n",
    "except psycopg2.Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe is inserted\n"
     ]
    }
   ],
   "source": [
    "# Inserting the data from the dataframe into the corresponding table\n",
    "execute_df_values(conn, sets_df, 'sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
